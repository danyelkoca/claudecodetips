
Claude with thinking time is a different beast than Claude rushing to answer. This single habit will improve your results more than any other.

## How Extended Thinking Works

When Claude uses extended thinking, it benefits from "serial test-time compute." The model generates a hidden chain-of-thought internally before producing its final answer. [Anthropic's research](https://www.anthropic.com/news/visible-extended-thinking) shows Claude's accuracy improves logarithmically as thinking tokens increase. On the 2024 AIME math exam, giving Claude a larger thinking budget led directly to higher scores.

The catch: thinking longer isn't always better. [Anthropic's inverse scaling research](https://alignment.anthropic.com/2025/inverse-scaling/) found that Claude models "become increasingly distracted by irrelevant information" as reasoning extends. Extended thinking can actually hurt performance on certain tasks, particularly those with distractors or spurious patterns. Match the thinking level to the problem, not the other way around.

## The Ultrathink Keyword

In Claude Code, include `ultrathink` in your prompt to allocate the maximum thinking budget of 31,999 tokens:

```
ultrathink. Design a caching layer for our API with invalidation strategy.
```

According to [Claude Code's official documentation](https://code.claude.com/docs/en/common-workflows), `ultrathink` both allocates the thinking budget AND semantically signals Claude to reason more thoroughly. Other phrases like "think", "think hard", and "think more" are interpreted as regular prompt instructions and don't allocate tokens.

Earlier in 2025, Claude Code had a three-tier system (think/megathink/ultrathink with 4K/10K/32K tokens). That's been simplified. Now it's binary: thinking is either on (31,999 tokens) or off (0 tokens). Ultrathink enables it for a single request.

## Enabling Thinking Mode

Three ways to enable extended thinking in Claude Code:

**1. Per-request with ultrathink:**
```
ultrathink. Debug this authentication flow.
```

**2. Toggle with Tab key:**
Press `Tab` during any session to toggle thinking on/off. The state persists across sessions.

**3. Global config:**
Run `/config` and enable thinking mode globally. This sets `alwaysThinkingEnabled` in `~/.claude/settings.json`.

**4. Environment variable:**
```bash
export MAX_THINKING_TOKENS=16000
```
This overrides all other settings and lets you set custom token budgets.

## Model Defaults

Sonnet 4.5 and Opus 4.5 have thinking enabled by default. All other models have thinking disabled by default. Check your current model with `/model`.

Opus 4.5 also supports an [effort parameter](https://platform.claude.com/docs/en/build-with-claude/effort) (via API) that controls how many tokens Claude uses across the entire response, not just thinking. Set effort to "low", "medium", or "high" to trade thoroughness for speed. At medium effort, Opus 4.5 matches Sonnet 4.5's best SWE-bench score while using 76% fewer tokens.

## When to Use Ultrathink

Reserve it for problems that genuinely need deep reasoning:

- Architectural decisions that affect your codebase for months
- Race conditions and timing bugs
- Performance optimization requiring root cause analysis
- Complex refactoring across multiple files
- Debugging failures where the obvious answer isn't working

Don't use it for routine tasks. A simple edit doesn't need 31,999 tokens of reasoning. You're paying for every thinking token.

## Viewing Claude's Thinking

Press `Ctrl+O` to toggle verbose mode. Internal reasoning appears as gray italic text.

Since v2.0.0, thinking output isn't shown in verbose mode by default. You need to toggle it on to see what Claude is actually reasoning through. This is useful for debugging when Claude's answers seem off.

## Benchmark Performance

Extended thinking drives significant improvements. With Claude 3.7 Sonnet:

- **[MATH 500](https://www.anthropic.com/news/visible-extended-thinking)**: 96.2% accuracy (vs 82.2% without thinking)
- **[GPQA Diamond](https://www.datacamp.com/blog/claude-3-7-sonnet)**: 84.8% on graduate-level science (physics subscore: 96.5%)
- **[SWE-bench Verified](https://www.anthropic.com/news/claude-3-7-sonnet)**: 70.3% with scaffolding (vs 49% on Claude 3.5 Sonnet)

Opus 4.5 pushes SWE-bench to [80.9%](https://www.anthropic.com/news/claude-opus-4-5), the first model to break 80%.

## Practical Guidance

**Start with high-level instructions.** Anthropic's [extended thinking tips](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/extended-thinking-tips) recommend asking Claude to "think thoroughly" rather than prescribing step-by-step reasoning. The model's approach to problems often exceeds what you'd prescribe.

Instead of:
```
Think through this step by step:
1. First, identify the variables
2. Then, set up the equation...
```

Try:
```
ultrathink. Consider multiple approaches and show your complete reasoning.
Try different methods if your first approach doesn't work.
```

**Ask Claude to verify its work.** Include a simple instruction like "verify your solution with test cases before declaring complete." Self-checking reduces errors significantly.

**Use multishot prompting.** If you provide examples with `<thinking>` or `<scratchpad>` tags showing how to reason through problems, Claude follows similar patterns in its extended thinking.

## Real-World Example

I was debugging a race condition in a WebSocket handler. Standard prompting produced band-aid fixes that masked the symptom. Adding ultrathink made Claude trace the actual state flow and find the root cause: a `useEffect` cleanup firing after a new connection was already established.

```
ultrathink. Debug this race condition in the WebSocket handler.
Trace the state through the full connection lifecycle.
Don't just fix the symptom - find why it's happening.
```

The difference was night and day. Without thinking time, Claude patched the race. With it, Claude found the architectural flaw.

## Critical Limitations

**Claude Code only.** The ultrathink keyword works in Claude Code's CLI because it triggers programmatic token budget allocation. If you try it in Claude.ai's web interface or the API, it's just text in your prompt with no special processing.

**Token costs.** Ultrathink uses up to 31,999 tokens of reasoning. You're charged for all of it, even though the output shows summarized thinking. Use it for the 10% of problems that genuinely need it.

**Diminishing returns.** Anthropic recommends starting at 1,024 tokens (the minimum) and increasing incrementally. For most tasks, a few thousand tokens of thinking provides most of the benefit. Going to 32K only helps for genuinely complex problems.

**Inverse scaling.** On tasks with distractors, extended thinking can make Claude perform worse. If Claude seems to be overthinking and getting confused, try reducing the thinking budget or using standard mode.

## The Bottom Line

Ultrathink is a scalpel, not a hammer. For routine work, don't use it. For hard problems, it transforms Claude from a fast-but-shallow assistant into a collaborator that catches edge cases and proposes actual solutions.

Toggle thinking on by default with Sonnet 4.5 or Opus 4.5. Use `ultrathink` explicitly when you need Claude to really dig in. Watch your token costs, and don't overthink simple tasks.
