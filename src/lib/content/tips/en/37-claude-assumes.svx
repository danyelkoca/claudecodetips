---
id: 37
title: "Claude Assumes Instead of Asking"
section: pitfalls
summary: "Ambiguous requirement? Claude picks an interpretation and runs with it."
isFree: false
---

Ambiguous requirement? Claude picks an interpretation and runs with it. Wrong guess = wasted work. This is one of the most expensive pitfalls in AI-assisted development.

## The Cost of Wrong Assumptions

When Claude assumes instead of asking, consequences compound:

- Hours lost implementing features that don't match your intent
- Architectural decisions that become difficult to change
- Refactoring that touches files you never intended to modify
- Context gaps that propagate through subsequent changes

The [2025 State of AI Code Quality report from Qodo](https://www.qodo.ai/reports/state-of-ai-code-quality/) found that 65% of developers report AI misses relevant context during refactoring, the highest of any coding task. Context gaps were cited more often than hallucinations as the cause of poor code quality. The more a task depends on understanding your specific requirements, the more likely Claude is to miss the mark.

## Why Claude Assumes Instead of Asks

This behavior is baked into how language models are trained.

[Research from NYU and UT Austin](https://arxiv.org/abs/2410.13788), published at ICLR 2025, explains why: "Existing LLMs often respond by presupposing a single interpretation of such ambiguous requests." The root cause is how preference data gets labeled. Human raters judge responses in isolation, without considering what happens in the next turn. An answer that "looks complete" beats a question asking for clarification, even when that question would lead to better results.

There's also the abstention problem. The fundamental training task, predict the next token, never included an option to say "I don't know." [AbstentionBench research](https://arxiv.org/abs/2506.09038) (June 2025) found that abstention remains "an unsolved problem, and one where scaling models is of little use." Bigger models don't get better at knowing when to stop and ask.

The researchers found something counterintuitive: reasoning-focused models like o1 actually get worse at abstention by about 24%. They "hallucinate missing context and provide definitive final answers even when their reasoning chains express uncertainty."

## How This Differs from Being a YES MAN

This is the opposite of Tip 36 (Claude is a YES MAN):

- **YES MAN** is reactive: Claude validates YOUR bad ideas when you suggest them
- **Assumes** is proactive: Claude invents things you DIDN'T ask for

YES MAN follows your lead uncritically. Assumes runs ahead without asking for direction. Both are problems, but they require different solutions.

## The AskUserQuestion Tool

[Claude Code v2.0.21](https://claudelog.com/claude-code-changelog/) (October 2025) added the AskUserQuestion tool. This is a structured way for Claude to pause execution and ask clarifying questions.

Instead of guessing, Claude can now say: "I see three ways to fix this API. Do you prefer A, B, or C?" This represents a deliberate architectural decision by Anthropic. Rather than relying on system prompt instructions alone, they created a dedicated tool because structured questioning produces better outcomes than free-form prompting.

The tool presents multiple-choice questions with descriptions, gathers multiple answers in one interaction, and lets Claude proceed with confidence once clarified.

But Claude still defaults to assuming unless you tell it otherwise.

## Fix This in CLAUDE.md

Add explicit instructions to your project's CLAUDE.md:

```markdown
## Requirements Handling
- When in doubt, ask. Never make assumptions about unclear requirements.
- Ask clarifying questions before making architectural changes.
- If a requirement has multiple valid interpretations, present options before proceeding.
- Never assume technology choices, data models, or design patterns without confirmation.
```

This gives Claude explicit permission to ask questions. Without it, the default behavior is to guess.

## The Confidence Threshold Technique

A powerful prompting pattern: [instruct Claude to ask questions until it reaches a confidence threshold](https://www.lewis-lin.com/blog/the-secret-weapon-for-better-ai-responses-ask-until-youre-95-sure).

```
Write a guide on setting up a home network.
Ask clarifying questions until you are 95% sure you can complete the task successfully.
```

This transforms one-directional interactions into collaborative conversations. Claude must gauge its own comprehension before proceeding.

Adjust the threshold based on task criticality:
- 80% for brainstorming and exploration
- 95% for feature implementation
- 99% for production-critical changes

The technique works because it gives Claude an explicit metric to hit. Without a threshold, Claude defaults to "I'll figure it out."

## Spec-Driven Development

For complex features, write requirements in a file before prompting Claude:

```markdown
<!-- requirements.md -->
## User Authentication Feature

### Must Have
- Email/password login
- Password reset via email
- Session expiry after 24 hours

### Must NOT Have
- Social login (out of scope)
- Two-factor authentication (phase 2)

### Open Questions
- Where should sessions be stored? (Redis vs database)
- Should we support "remember me" functionality?
```

Then tell Claude: "Read requirements.md. For any open questions, ask me before proceeding."

This approach:
- States explicit choices, removing guesswork
- Identifies deliberate exclusions
- Flags items needing your input

The "Open Questions" section is key. It tells Claude exactly where you want its input.

## Give Claude an Escape Hatch

In your CLAUDE.md, provide explicit guidance for uncertainty:

```markdown
## When Uncertain
If you are unsure about any requirement:
1. Ask a clarifying question, OR
2. Propose a short plan for review, OR
3. Present options with trade-offs

Never push large speculative changes without confirmation.
```

This tells Claude what to do instead of guessing. Without an alternative action, Claude defaults to proceeding with assumptions.

## Practical Examples

**Bad prompt:**
```
Add user authentication to the app
```

Claude assumes: OAuth vs JWT vs sessions, where to store tokens, middleware structure, password hashing algorithm, session duration, and more.

**Good prompt:**
```
Add user authentication to the app.

Before implementing, ask me about:
- Authentication method (OAuth, JWT, session-based)
- Password requirements and hashing
- Session storage and expiry
- What endpoints need protection

Don't write code until I've answered these questions.
```

**Bad prompt:**
```
Optimize the database queries
```

Claude assumes: which queries matter, what "optimized" means, acceptable trade-offs.

**Good prompt:**
```
Optimize the database queries.

First, identify the 3 slowest queries and ask me:
- Which ones actually matter for our use case?
- What query time is acceptable?
- Can we add indexes or change the schema?
```

## Recognize When Claude Is Assuming

Watch for these signals that Claude is making assumptions:

- Immediate implementation without questions
- Phrases like "I'll assume you want..." or "Assuming we're using..."
- Technology choices you didn't specify
- Edge case handling you didn't request
- Features beyond what you asked for

When you see these, interrupt with Escape and redirect: "Stop. I didn't specify that. What made you choose this approach? Ask me instead of assuming."

I've found that calling out assumptions explicitly trains Claude for the rest of the session. Once interrupted, it tends to ask more questions on subsequent tasks.

## The Long-Term Fix

For persistent improvement, add this to your global `~/.claude/CLAUDE.md`:

```markdown
## Communication Style
- Treat unclear requirements as blockers, not opportunities to guess
- A wrong implementation costs more than a clarifying question
- When you notice yourself assuming, stop and ask instead
- List your assumptions explicitly before any implementation
```

Then reinforce with project-specific instructions as needed.

## The Anthropic Docs Perspective

[Anthropic's official prompting guide](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/claude-4-best-practices) for Opus 4.5 confirms this behavior: Claude can be overly conservative about asking questions. Their recommended fix is direct prompting. They suggest including instructions like:

```
If the user's intent is unclear, infer the most useful likely action and proceed,
using tools to discover any missing details instead of guessing.
```

Or the opposite, if you want Claude to be more hesitant:

```
When the user's intent is ambiguous, default to providing information,
doing research, and providing recommendations rather than taking action.
```

The model responds reliably to direct guidance on this.

## The Bottom Line

Claude with assumptions is a fast typist making expensive guesses. Claude that asks questions is a collaborator building what you actually need.

The fix is explicit: give Claude permission to ask, provide an escape hatch for uncertainty, and state your confidence threshold. Every question asked saves an hour of rework.
