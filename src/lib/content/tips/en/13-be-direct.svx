---
id: 13
title: "Be Direct"
section: prompting
summary: "Be explicit about quantity - Claude tends to choose the easy way out."
isFree: false
---

Claude Code takes you literally. [Anthropic's prompting documentation](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/claude-4-best-practices) states that Claude 4.x models are "trained for more precise instruction following than previous generations." Earlier versions would infer intent and expand on vague requests. Opus 4.5, Sonnet 4.5, and Haiku 4.5 do exactly what you ask, nothing more. This is a feature, not a bug, but it requires you to be explicit.

## The Core Problem

Claude takes the path of least resistance. If you ask it to "research this topic," it might read 2 files and call it done. Ask it to "look into the bug," and it might glance at one function and propose a fix.

I've seen this pattern hundreds of times: vague prompt, minimal output, frustrated developer. The fix isn't a better model. It's telling Claude exactly what you want.

## Specify Quantities

Never leave quantities ambiguous. Be ruthlessly specific:

**Vague (bad):**
- "Research this"
- "Read the relevant files"
- "Check for edge cases"
- "Look at some examples"

**Direct (good):**
- "RESEARCH 5-10 websites before proposing a solution"
- "READ at least 15 files across the codebase"
- "CHECK every edge case, I expect at least 8"
- "FIND 3-5 similar implementations in the codebase"

The difference: vague prompts match millions of patterns where "AI guesses your intent." Specific prompts match exact constraints where "AI knows the requirement."

## Use Imperative Commands

Frame instructions as commands, not suggestions. Claude responds to directive language far better than polite requests.

**Passive (less effective):**
- "Can you suggest some changes?"
- "It might be good to check the tests"
- "Perhaps you could look at the error handling"
- "Would you mind researching this?"

**Imperative (more effective):**
- "CHANGE this function to improve performance"
- "RUN the tests and FIX any failures"
- "REWRITE the error handling to cover all cases"
- "RESEARCH this thoroughly, then IMPLEMENT"

When you say "can you suggest some changes," Claude might only provide suggestions rather than implementing them, even if implementation is what you intended. For Claude to take action, be explicit: "Make these edits" rather than "Can you suggest edits?"

## Add Explicit Constraints

Constraints act as guardrails. They prevent unwanted outputs and focus Claude on your exact specifications.

**Types of constraints to specify:**
- **Length:** "Write a function under 50 lines"
- **Format:** "Return the data as JSON, not markdown"
- **Scope:** "Only modify files in src/components/"
- **Exclusions:** "Do NOT use external libraries"
- **Quality:** "Ensure O(n) time complexity or better"

**Example transformation:**

Bad: "Refactor this code"

Good: "Refactor this code with these constraints:
1. Preserve all existing functionality
2. Reduce function length to under 30 lines each
3. Use existing utility functions from src/utils/
4. Do NOT add new dependencies
5. Add JSDoc comments for all public functions"

## Prevent Incomplete Output

Claude sometimes provides truncated snippets, placeholders like `// rest of code here`, or summaries instead of implementations. I've had Claude return a 20-line skeleton for a 200-line refactor. Counter this explicitly:

**Anti-truncation phrases:**
- "You MUST provide a complete, end-to-end implementation"
- "Do NOT use ellipses, comments, or pseudocode as placeholders"
- "Do NOT truncate or provide partial implementations"
- "Your output should be ready to run without modifications"
- "I want the COMPLETE solution, not a summary"

Add these to your CLAUDE.md file so you don't repeat them every session.

## Research Before Coding

Claude wants to write code immediately. [Anthropic's best practices](https://www.anthropic.com/engineering/claude-code-best-practices) note: "Steps #1-#2 are crucial, without them, Claude tends to jump straight to coding a solution. While sometimes that's what you want, asking Claude to research and plan first significantly improves performance."

Force research before implementation:

**Bad:** "Fix the authentication bug"

**Good:** "Before writing any code:
1. READ all files related to authentication (at least 5)
2. TRACE the auth flow from login to session creation
3. IDENTIFY the exact line where the bug occurs
4. LIST 3 potential root causes
THEN propose a fix"

The phrase "before writing any code" is the key. Without it, Claude starts typing solutions before understanding the problem.

## The Role-Goal-Constraints Framework

Structure complex prompts with this proven template:

```
ROLE: You are a senior TypeScript developer with 10 years of experience.

GOAL: Refactor the authentication module to use JWT tokens instead of session cookies.

CONSTRAINTS:
- Read ALL existing auth files before making changes (minimum 8 files)
- Preserve backwards compatibility with existing API consumers
- Add thorough test coverage (minimum 15 test cases)
- No new dependencies except jsonwebtoken
- Complete within the src/auth/ directory only
```

This structure works because Claude can't shortcut any step. Each constraint is measurable.

## Quantified Task Examples

Here are real-world examples of adding specificity:

| Vague | Direct |
|-------|--------|
| "Write tests" | "Write 10 unit tests covering happy path, error cases, and edge cases" |
| "Optimize this" | "Reduce execution time by 50%, targeting the nested loops on lines 45-60" |
| "Document this" | "Add JSDoc comments to all 12 public functions with @param and @returns" |
| "Review the code" | "Review for: security vulnerabilities (OWASP top 5), performance issues, and code style violations" |
| "Explore the codebase" | "Read at least 20 files, map the architecture, and identify the 5 core modules" |

## Self-Verification Instructions

Ask Claude to verify its own work:

- "After implementing, RUN the tests and CONFIRM they pass"
- "CHECK your solution against ALL requirements before responding"
- "RATE your confidence in this solution on a scale of 1-10"
- "LIST any assumptions you made that I should verify"

## When Claude Still Takes Shortcuts

Sometimes explicit instructions aren't enough. Claude still returns minimal output. Escalation tactics:

1. **Use thinking triggers:** Add "ultrathink" to allocate more reasoning budget
2. **Break into steps:** "FIRST do X. WAIT. THEN do Y. WAIT. FINALLY do Z."
3. **Request confirmation:** "Before proceeding, LIST what you will do"
4. **Start fresh:** Long sessions degrade quality. Use `/clear` and try again.

If you're constantly fighting for complete output, the issue might be context pollution from earlier in the session. Fresh context often fixes what no amount of emphasis can.

## Real Example: Debugging a Payment Flow

Here's how directness changes outcomes. I was debugging a Stripe webhook that silently failed.

**First attempt (vague):**
```
The webhook isn't working. Can you take a look?
```

Claude glanced at one file, proposed a generic error handler, and moved on. Useless.

**Second attempt (direct):**
```
Debug the Stripe webhook failure. Before writing any code:
1. READ src/routes/api/webhooks/stripe/+server.js
2. READ src/lib/server/firebase-admin.js
3. TRACE the data flow from webhook receipt to database write
4. IDENTIFY where the silent failure occurs
5. LIST all error conditions that could cause silent failures

Then propose a fix with proper error logging.
```

Claude found the actual bug: a missing `await` on a Firestore write that caused the function to return before the write completed. The webhook reported success while data was lost.

Same problem. Same model. Different prompt. One produced a fix-nothing suggestion, the other found the root cause.

## The Cost of Vagueness

Vague prompts feel faster. You type less. But you pay for it in iterations.

A direct prompt with constraints takes maybe 30 seconds longer to write. A vague prompt that produces wrong output costs you 5 minutes of back-and-forth, or worse, bugs you don't catch until production.

Directness is not about perfect prompts. It's about saying what you actually want. Numbers. Constraints. Actions. That's it.
