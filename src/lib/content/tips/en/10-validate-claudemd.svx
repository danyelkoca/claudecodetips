
Claude forgets its own instructions. As conversations grow longer, rules defined at the start receive progressively less attention. [Research from Microsoft and Salesforce](https://arxiv.org/abs/2505.06120) found that LLM performance drops from 90% in single-turn to 65% in multi-turn conversations, a 25-point decline. This pattern held across all 15 models tested, including Claude. Once Claude goes off track, it rarely recovers.

The fix: before Claude executes a plan, ask it to verify against your CLAUDE.md rules. This forces Claude to re-read your instructions at the moment they matter most.

## Why Instructions Decay

Large language models do not "remember" conversations. They read the entire history as one document every time they respond. Your instructions, sitting at the beginning, gradually lose attention weight as the conversation grows.

Claude Code makes this worse. It injects a system reminder with your CLAUDE.md stating: "this context may or may not be relevant to your tasks. You should not respond to this context unless it is highly relevant to your task." This causes Claude to de-prioritize instructions it deems non-essential. The more task-specific your rules appear, the higher the chance Claude ignores them for generic tasks.

**Signs Claude is ignoring your CLAUDE.md:**

- Uses camelCase when you said snake_case
- Creates a new utility function when three similar ones exist
- Skips tests "to save time" despite your TDD requirement
- Names files inconsistently with the rest of your project
- Adds dependencies you explicitly banned

## The Validation Workflow

Before approving any plan for execution, insert a validation checkpoint:

**Step 1: Claude presents a plan**

After analysis in plan mode, Claude proposes an implementation approach.

**Step 2: Request explicit validation**

```bash
> Before you proceed, validate this plan against CLAUDE.md. Check each rule. Does this plan follow all the rules? List any violations.
```

**Step 3: Review Claude's validation response**

Claude re-reads CLAUDE.md and audits the plan against each rule. It will either confirm compliance or identify gaps.

**Step 4: Iterate or approve**

If violations exist, ask Claude to revise the plan. If compliant, approve execution.

Here's what this looks like in practice:

```
You: Validate this plan against CLAUDE.md before proceeding.

Claude: Checking against CLAUDE.md rules...
- Rule: "Never create new utilities if similar ones exist"
  VIOLATION: Plan creates new formatDate() but src/utils/date.ts has formatTimestamp()
- Rule: "Follow existing naming patterns"
  PASS: Component names match existing pattern
- Rule: "Tests required for all new functions"
  PASS: Plan includes test file

One violation found. Revising plan to use existing formatTimestamp()...
```

The difference between Claude saying "I'll follow your rules" and actually proving it.

## Validation Prompts That Work

Use these prompts at key checkpoints:

**Pre-implementation validation:**

```bash
> Validate this plan against CLAUDE.md. Does it follow all the rules? List each rule and whether this plan complies.
```

**Post-implementation validation:**

```bash
> Check the changes you just made against CLAUDE.md rules. Identify any deviations. Say PASS or FAIL.
```

**Completion analysis (PDCA framework):**

```bash
> Before we close this task, verify: All tests passing? Documentation accurate? Code coverage adequate? TDD discipline maintained? No TODO implementations remaining? Ready to close: Yes or No with reasoning.
```

**Constraint verification:**

```bash
> Before implementing, verify this approach against these constraints: [list from CLAUDE.md]. Confirm each one is satisfied.
```

## What to Validate Against

Give Claude concrete rules to validate against. Checkbox format works well because violations become obvious:

```
> Validate this plan against these rules:
> - [ ] Read all relevant files before modifying
> - [ ] No new utilities if similar ones exist
> - [ ] Follows existing patterns in the codebase
> - [ ] Tests written and passing
```

When you ask Claude to validate, it walks through each item. If you have a Final Checklist section in your CLAUDE.md, point Claude to it directly.

## Advanced Validation Techniques

### Recursive Rule Display

Force Claude to display your rules at the start of every response. This creates multiple attention anchors throughout the conversation:

```markdown
## Behavioral Rules

<rules>
1. Always confirm before creating or modifying files
2. Report your plan before executing commands
3. Follow all patterns documented in CLAUDE.md
4. Display these rules at the start of every response
</rules>
```

The self-referential rule (item 4) ensures the rules persist in recent context. [Anthropic recommends XML tags](https://docs.anthropic.com/en/docs/use-xml-tags) for structuring prompts because Claude was trained to pay special attention to them. Clear boundaries between sections reduce the chance Claude mixes up instructions with context.

### The Reflection Pattern

Apply self-critique before finalization:

```bash
> Review your proposed solution. What could go wrong? What edge cases exist? Does this truly follow all CLAUDE.md rules, or did you make compromises? Be critical.
```

This triggers Claude's reflection capabilities, a second pass where it evaluates its own output for accuracy and quality. [Research on Self-Refine](https://arxiv.org/abs/2303.17651) found outputs improved by ~20% on average when LLMs critiqued and refined their own work. Worth the extra tokens when correctness matters.

### Periodic Reminder System

For long sessions, insert reminders every few messages:

```bash
> Reminder: Re-read CLAUDE.md rules before your next response. What are the key constraints for this project?
```

This counteracts instruction decay by periodically refreshing Claude's attention on your rules.

## When to Validate

**Always validate:**

- Before exiting plan mode
- After completing multi-file changes
- Before committing code
- When switching between major tasks
- After extended conversation (10+ messages)

**Skip validation for:**

- Single-line fixes with obvious correctness
- Trivial changes that do not touch architecture
- Repeated patterns Claude has already validated

## Common Validation Failures

**Shallow validation**: Claude says "plan follows all rules" without actually checking each one. Fix by asking for explicit per-rule confirmation.

**Selective validation**: Claude validates against rules it remembers, ignoring ones that drifted from context. Fix by asking Claude to re-read CLAUDE.md first.

**Optimistic interpretation**: Claude interprets rules loosely to claim compliance. Fix by asking for specific evidence: "Show me which existing pattern you are following."

**Validation theater**: Claude performs validation steps but proceeds despite violations. Fix by requiring explicit PASS/FAIL and blocking execution on FAIL.

## Making Validation Automatic

Add validation requirements to your CLAUDE.md itself:

```markdown
## Mandatory Validation

Before implementing any plan:
1. Re-read this entire CLAUDE.md file
2. List each rule that applies to the current task
3. Confirm the plan satisfies each rule
4. If any rule is violated, revise the plan before proceeding
```

This makes validation part of Claude's standard workflow rather than something you must remember to request.

## The Bottom Line

Claude is not a perfect rule-follower. Instruction decay is real. The fix is validation checkpoints where you force Claude to re-read your rules before executing.

I've found this catches 80% of rule violations before they happen. Claude will say "I followed all the rules" without checking. Make it prove compliance. Ask for per-rule confirmation.

One minute of validation saves ten minutes of cleanup. Make it a habit.
