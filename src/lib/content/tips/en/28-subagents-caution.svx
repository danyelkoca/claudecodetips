
Subagents can explore your entire codebase, research documentation, and execute multi-step tasks without polluting your main context window. But there is a fundamental tradeoff: **when a subagent reports back, you only get a summary, not the full picture.**

This is not a bug. It is an architectural choice. Understanding it determines whether subagents help or hurt your work.

## How Subagents Work

When you invoke a subagent (via `Task(...)` or when Claude automatically delegates), the following happens:

1. **A new context window opens.** The subagent gets its own isolated 200K token context, completely separate from your main conversation.

2. **The subagent works independently.** It reads files, searches code, and reasons through problems, all within its isolated environment.

3. **Only a summary returns.** When complete, the subagent distills its work into a condensed response that gets injected into your main conversation.

This isolation is intentional. If every file the subagent read flooded back into your main context, you would hit context limits almost immediately. The summary acts as a compression layer.

## The Three Built-in Subagent Types

[Claude Code's built-in subagents](https://code.claude.com/docs/en/sub-agents) have different defaults:

| Agent | Model | Purpose | Context Inheritance |
|-------|-------|---------|---------------------|
| **Explore** | Haiku | Fast, read-only codebase searching | Fresh slate (no prior context) |
| **Plan** | Sonnet | Research during planning phase | Inherits full conversation |
| **General-Purpose** | Sonnet | Complex multi-step tasks with modifications | Inherits full conversation |

**Why Explore uses Haiku:** Speed and cost. When scanning dozens of files, [Haiku 4.5 runs 2-4x faster at about one-third the cost](https://www.anthropic.com/news/claude-haiku-4-5) of Sonnet. The tradeoff is less nuanced reasoning, which is acceptable for search tasks, problematic for architectural decisions.

**Why Explore starts fresh:** Search tasks are often independent. A subagent looking for "all authentication-related files" does not need your conversation history about payment processing. Starting fresh keeps context focused and avoids token overhead.

## The Fundamental Problem: Lossy Compression

When a subagent reads 50 files and returns a summary, information is inevitably lost. It is mathematically impossible to preserve all detail when compressing 100K tokens of file contents into a 2K token summary.

**What gets preserved:**
- High-level patterns and structure
- Explicit findings ("Found 12 usages of deprecated API")
- File paths and locations
- General conclusions

**What gets lost:**
- Subtle implementation details
- Edge cases buried in conditionals
- Non-obvious dependencies
- Context that seemed unimportant but matters later
- The nuanced understanding that comes from reading code yourself

[Factory.ai's research on context compression](https://factory.ai/news/evaluating-compression) found that even the best methods score only 2.19-2.45 out of 5.0 on artifact tracking (remembering which files were modified, exact locations, specific values). **The things that matter most for debugging are the hardest to preserve in summaries.**

## The "Game of Telephone" Problem

In multi-agent architectures, information passes through multiple compression stages:

```
Raw Code (100K tokens)
    ↓ Subagent reads and summarizes
Summary 1 (2K tokens)
    ↓ Main agent processes
Main Agent's Understanding (lossy)
    ↓ You ask a follow-up question
Summary 2 (even more compressed)
```

Each stage introduces distortion. By the time information reaches your conversation, subtle but critical details may have vanished. [Anthropic's multi-agent research system](https://www.anthropic.com/engineering/multi-agent-research-system) addresses this by having subagents "call tools to store their work in external systems, then pass lightweight references back to the coordinator." They explicitly acknowledge the degradation problem.

## When Subagents Work Well

### Research and Exploration

Subagents excel at broad codebase exploration:

```
"Use subagents to find all places where user permissions are checked"
```

The Explore agent scans rapidly across files, returning a map of locations. For this use case, you do not need the full implementation details. You just need pointers to where to look next.

### Documentation Gathering

When Claude needs to fetch and synthesize external documentation:

```
"Research the latest Stripe API changes for subscription handling"
```

A subagent can read multiple doc pages and return a focused summary. You get the essential information without 50K tokens of API documentation cluttering your context.

### Parallel Investigation

When investigating multiple independent areas:

```
"Use 3 subagents to explore: authentication, database schema, and API routes"
```

Each explores its domain in parallel. You get three summaries instead of waiting for sequential exploration.

### Context-Expensive Tasks

Tasks requiring extensive reading that would otherwise exhaust your main context:

```
"Analyze all 200 test files and identify which ones test deprecated functionality"
```

The subagent does the exhaustive reading. Your main context receives only the actionable findings.

## When to Have Main Agent Read Directly

### Critical Architecture Decisions

If you are deciding how to structure a core system, do not rely on summaries:

```
"Read src/lib/auth/session.ts and src/lib/auth/middleware.ts directly.
I need to understand the exact session handling flow before modifying it."
```

The main agent reading directly means those files are in context when you make decisions. No compression, no lost details.

### Debugging Complex Issues

When tracking down subtle bugs, every detail matters:

```
"Read the failing test file and the implementation file it tests.
Do not use subagents. I need you to see the exact code."
```

Subagent summaries might say "the test checks user validation" but miss that it specifically validates email format with a regex that has a known edge case.

### Code You Will Modify

Before editing any file, the main agent should read it:

```
"Read src/components/PaymentForm.tsx before making changes.
I want the full implementation in context, not a summary."
```

Editing based on a subagent summary is like performing surgery after someone described the patient over the phone.

### When Details Determine Correctness

Some code cannot be summarized without losing critical information:

- Configuration files with precise values
- Migration files with exact schema changes
- Security code where every condition matters
- Integration code with specific API contracts

## Practical Decision Framework

| Situation | Use Subagent? | Reason |
|-----------|--------------|--------|
| "Where is authentication handled?" | Yes | Exploration, locations are enough |
| "How exactly does authentication work?" | No | Need implementation details |
| "Find all usages of deprecated API" | Yes | List of locations is sufficient |
| "Refactor this deprecated API usage" | No | Must understand each usage's context |
| "What files relate to payments?" | Yes | Discovery phase |
| "Fix the payment calculation bug" | No | Need exact code in context |
| "Research React 19 migration steps" | Yes | External doc synthesis |
| "Apply React 19 changes to our codebase" | No | Must see our specific patterns |

## Let the Main Agent Decide

The main agent should control when to delegate. Let it analyze the task, decide which subtasks benefit from delegation, spawn subagents using `Task(...)`, and aggregate results with awareness of what was summarized.

This keeps holistic reasoning in the main agent. It sees the full picture and makes informed decisions about what to delegate vs. handle directly. Overly specialized subagents like "PythonTests" or "SecurityAudit" hide context from your main agent, fragmenting its understanding of how changes ripple across the codebase.

## Signs You Are Over-Relying on Subagents

| Symptom | What It Means |
|---------|---------------|
| Claude seems confused about file contents | It read a summary, not the actual code |
| Suggestions do not match your codebase patterns | Subagent missed your conventions |
| Claude asks questions you know it "explored" | Key details were lost in summarization |
| Fixes break other functionality | Dependencies were not visible in the summary |
| You keep saying "no, look at the actual file" | Main agent needs direct access |

## Best Practices

### 1. Use Subagents for Discovery, Main Agent for Execution

Subagent: "Find all files that import the deprecated utility"
Main agent: "Read those specific files and implement the migration"

### 2. Request Explicit File Reads After Subagent Exploration

After subagent returns locations:
```
"Now read the three most complex files from that list directly.
I need their full implementation in context before we proceed."
```

### 3. Be Explicit About What You Need

Instead of:
```
"Investigate the auth system"
```

Say:
```
"Use a subagent to find auth-related files, then read the core
auth middleware directly so I can understand the exact flow."
```

### 4. Preserve Critical Context in External Files

For complex multi-session work, have subagents write findings to files:
```
"Write your analysis to docs/auth-analysis.md with specific
file paths and code snippets. I will read this file directly."
```

Files preserve detail that summaries lose.

### 5. Verify Before Trusting

After a subagent summary, spot-check critical details:
```
"Read src/lib/auth.ts lines 145-180 directly. I want to verify
the session handling matches what the subagent described."
```

## The Context Isolation Tradeoff

Subagent context isolation provides:
- **Context preservation** - Your main conversation stays focused
- **Parallel capacity** - Multiple explorations without serial bottlenecks
- **Cost efficiency** - Research tokens do not inflate your main context

But costs:
- **Detail loss** - Summaries cannot capture everything
- **Reasoning fragmentation** - Holistic understanding is harder
- **Invisible work** - You cannot see the subagent's thinking
- **Verification overhead** - You may need to re-read files anyway

The tradeoff is not good or bad. It depends on your task.

## Key Takeaways

- **Subagent summaries are lossy compression.** Important details can and will be lost. This is architectural, not a bug.

- **Use subagents for exploration, main agent for critical work.** Find things with subagents. Understand and modify things with the main agent's direct file access.

- **The main agent in context = full fidelity.** When the main agent reads a file, that file is in context for all subsequent reasoning. No compression, no loss.

- **Do not edit code you have not read.** If Claude is modifying a file based on a subagent summary, have it read the file directly first.

- **Verify subagent findings.** Spot-check critical details by having the main agent read key files directly.

- **Think about information flow.** Every layer of summarization loses detail. Minimize layers for critical decisions.

The developers who master Claude Code treat subagents as scouts, not surgeons. Scouts map the territory. But when it is time to operate, you want the full picture in front of you.
