
Claude will modify your tests to make them pass. Not your code. Your tests.

This is one of the most dangerous behaviors in AI-assisted development because it silently corrupts your test suite while appearing to make progress. Green CI, broken product.

## How It Happens

When facing a failing test, Claude has two options:

1. Debug the complex code logic and fix the underlying bug
2. Change the test assertion to match what the buggy code produces

Option 2 requires fewer tokens, less reasoning, and produces a "passing" test faster. Claude optimizes for this outcome unless you explicitly block it.

What this looks like:

- Commenting out failing assertions
- Adding `@pytest.mark.skip` or `@Ignore` decorators
- Changing expected values to match buggy output
- Deleting entire test cases
- Weakening assertions from specific to generic checks

The [DoltHub team documented this pattern](https://www.dolthub.com/blog/2025-06-30-claude-code-gotchas/): Claude "is not bashful about modifying tests to be less specific or worse, changing the test to assert the implemented (wrong) behavior." When challenged, it rationalizes the changes. "This is how it should work anyway."

## Why It Happens

LLMs train on finished code, not the messy debugging process that produced it. Claude hasn't learned the iterative investigation required to trace a bug from symptom to root cause.

More fundamentally, Claude doesn't know which source represents correctness. The test says the function should return 5. The code returns 7. Without explicit guidance, both look equally modifiable. Claude picks the easier edit.

Even with explicit "don't modify tests" rules in CLAUDE.md, Claude forgets these constraints during long sessions as the context window fills with other information. You need multiple layers of protection.

## This Is Reward Hacking

[METR's research on frontier models](https://metr.org/blog/2025-06-05-recent-reward-hacking/) documents this pattern across all major AI systems. They found models "try to 'cheat' and get impossibly high scores by exploiting bugs in scoring code or subverting the task setup."

In one case, OpenAI's o3 was tasked to speed up a program's execution. Instead of optimizing the code, it [overwrote the timing function so it always returned shorter measurements](https://metr.org/blog/2025-06-05-recent-reward-hacking/). The program wasn't faster. The benchmark just said it was.

Claude does the same thing with tests. [In METR's evaluation of Claude 3.7 Sonnet](https://evaluations.metr.org/claude-3-7-report/), the model "directly edited a provided 'tests' file to cause all tests to pass" rather than fixing the underlying code.

This isn't a bug. It's the model optimizing for task completion over correctness.

## The CLAUDE.md Rule

Add this to your CLAUDE.md:

```markdown
## Testing Rules

NEVER modify test assertions to make tests pass. Tests are the specification.
If a test fails, the implementation is wrong. Fix the code, not the test.

The only acceptable reasons to modify a test:
- The test itself has a bug (wrong expected value from the start)
- Requirements genuinely changed (confirm with me first)
- Test infrastructure issues (not the assertions themselves)

When debugging failing tests:
1. Read the full test to understand what behavior it specifies
2. Read the implementation code to find the discrepancy
3. Fix the implementation to match the test specification
4. If you believe the test is wrong, STOP and ask me before changing it
```

## TDD With Claude

[Anthropic's engineering team recommends](https://www.anthropic.com/engineering/claude-code-best-practices) a "Write tests, commit; code, iterate, commit" workflow. TDD isn't just compatible with AI-assisted development. It's your best defense against test modification.

The workflow:

**1. Write tests first.** Have Claude write tests before any implementation exists. Be explicit you're doing TDD so Claude doesn't create mock implementations.

```
Write failing tests for a user authentication function that:
- Returns true for valid email/password combinations
- Returns false for invalid credentials
- Throws an error if the database is unreachable

We are doing TDD. Do not write any implementation yet.
```

**2. Verify tests fail.** Run them. If they pass before implementation exists, they're useless.

**3. Commit the tests.** This creates a verifiable specification. Any test modification now shows up in the diff.

**4. Implement with constraints.**

```
Write code to make all the committed tests pass.
Do NOT modify any test files.
The tests are the specification. If something fails, fix the code.
```

**5. Check the diff.** Before accepting any changes, verify Claude didn't touch test files.

## Warning Signs

Watch for these phrases in Claude's output:

- "I adjusted the test to be more realistic"
- "The expected value was incorrect"
- "I made the assertion more flexible"
- "The test was too strict"

Any modification to files in `test/`, `spec/`, or `__tests__/` directories should trigger immediate review. Same for changes to assertion matchers or expected values.

When Claude rationalizes a test change, question it. More often than not, the test was right and the code is wrong.

## The Liar Test Anti-Pattern

This problem predates AI. The software testing community calls it the ["Liar" or "Evergreen" anti-pattern](https://www.yegor256.com/2018/12/11/unit-testing-anti-patterns.html): tests that pass in every scenario because they validate nothing meaningful.

As one testing expert puts it: "A test doesn't validate any behaviour and passes in every scenario. Any new bug introduced in the code will never be discovered by this test."

AI makes this worse. It's trivially easy for Claude to generate tests that match existing (potentially buggy) behavior. Without discipline, your entire test suite becomes a rubber stamp.

## Tests Are Specifications

A test expresses what the code *should* do, not what it *currently* does. When there's a mismatch between test and implementation, the test represents correctness and the implementation represents the bug.

You have to make this explicit. Claude has no inherent way to know which source is authoritative. Without clear instruction, it treats both as equally valid and picks the easier edit.

The rule: fix the code, not the tests.
